static int vmw_cotable_resize(struct vmw_resource *res, size_t new_size)
{
	struct ttm_operation_ctx ctx = { false, false };
	struct vmw_private *dev_priv = res->dev_priv;
	struct vmw_cotable *vcotbl = vmw_cotable(res);
	struct vmw_bo *buf, *old_buf = res->guest_memory_bo;
	struct ttm_buffer_object *bo, *old_bo = &res->guest_memory_bo->tbo;
	size_t old_size = res->guest_memory_size;
	size_t old_size_read_back = vcotbl->size_read_back;
	size_t cur_size_read_back;
	struct ttm_bo_kmap_obj old_map, new_map;
	int ret;
	size_t i;
	struct vmw_bo_params bo_params = {
		.domain = VMW_BO_DOMAIN_MOB,
		.busy_domain = VMW_BO_DOMAIN_MOB,
		.bo_type = ttm_bo_type_device,
		.size = new_size,
		.pin = true
	};

	MKS_STAT_TIME_DECL(MKSSTAT_KERN_COTABLE_RESIZE);
	MKS_STAT_TIME_PUSH(MKSSTAT_KERN_COTABLE_RESIZE);

	ret = vmw_cotable_readback(res);
	if (ret)
		goto out_done;

	cur_size_read_back = vcotbl->size_read_back;
	vcotbl->size_read_back = old_size_read_back;

	/*
	 * While device is processing, Allocate and reserve a buffer object
	 * for the new COTable. Initially pin the buffer object to make sure
	 * we can use tryreserve without failure.
	 */
	ret = vmw_gem_object_create(dev_priv, &bo_params, &buf);
	if (ret) {
		DRM_ERROR("Failed initializing new cotable MOB.\n");
		goto out_done;
	}

	bo = &buf->tbo;
	WARN_ON_ONCE(ttm_bo_reserve(bo, false, true, NULL));

	ret = ttm_bo_wait(old_bo, false, false);
	if (unlikely(ret != 0)) {
		DRM_ERROR("Failed waiting for cotable unbind.\n");
		goto out_wait;
	}

	/*
	 * Do a page by page copy of COTables. This eliminates slow vmap()s.
	 * This should really be a TTM utility.
	 */
	for (i = 0; i < PFN_UP(old_bo->resource->size); ++i) {
		bool dummy;

		ret = ttm_bo_kmap(old_bo, i, 1, &old_map);
		if (unlikely(ret != 0)) {
			DRM_ERROR("Failed mapping old COTable on resize.\n");
			goto out_wait;
		}
		ret = ttm_bo_kmap(bo, i, 1, &new_map);
		if (unlikely(ret != 0)) {
			DRM_ERROR("Failed mapping new COTable on resize.\n");
			goto out_map_new;
		}
		memcpy(ttm_kmap_obj_virtual(&new_map, &dummy),
		       ttm_kmap_obj_virtual(&old_map, &dummy),
		       PAGE_SIZE);
		ttm_bo_kunmap(&new_map);
		ttm_bo_kunmap(&old_map);
	}

	/* Unpin new buffer, and switch backup buffers. */
	vmw_bo_placement_set(buf,
			     VMW_BO_DOMAIN_MOB,
			     VMW_BO_DOMAIN_MOB);
	ret = ttm_bo_validate(bo, &buf->placement, &ctx);
	if (unlikely(ret != 0)) {
		DRM_ERROR("Failed validating new COTable backup buffer.\n");
		goto out_wait;
	}

	vmw_resource_mob_detach(res);
	res->guest_memory_bo = buf;
	res->guest_memory_size = new_size;
	vcotbl->size_read_back = cur_size_read_back;

	/*
	 * Now tell the device to switch. If this fails, then we need to
	 * revert the full resize.
	 */
	ret = vmw_cotable_unscrub(res);
	if (ret) {
		DRM_ERROR("Failed switching COTable backup buffer.\n");
		res->guest_memory_bo = old_buf;
		res->guest_memory_size = old_size;
		vcotbl->size_read_back = old_size_read_back;
		vmw_resource_mob_attach(res);
		goto out_wait;
	}

	vmw_resource_mob_attach(res);
	/* Let go of the old mob. */
	vmw_user_bo_unref(&old_buf);
	res->id = vcotbl->type;

	ret = dma_resv_reserve_fences(bo->base.resv, 1);
	if (unlikely(ret))
		goto out_wait;

	/* Release the pin acquired in vmw_bo_create */
	ttm_bo_unpin(bo);

	MKS_STAT_TIME_POP(MKSSTAT_KERN_COTABLE_RESIZE);

	return 0;

out_map_new:
	ttm_bo_kunmap(&old_map);
out_wait:
	ttm_bo_unpin(bo);
	ttm_bo_unreserve(bo);
	vmw_user_bo_unref(&buf);

out_done:
	MKS_STAT_TIME_POP(MKSSTAT_KERN_COTABLE_RESIZE);

	return ret;
}