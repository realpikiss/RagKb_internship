#!/usr/bin/env python3
"""
ğŸ” MONITOR FULL EVALUATION - Real-time Progress Tracking
Monitor the progress of the full dataset evaluation
"""

import os
import time
import pandas as pd
from pathlib import Path

def monitor_evaluation():
    """Monitor evaluation progress in real-time"""
    
    results_dir = Path("evaluation_results")
    results_file = results_dir / "classification_results.csv"
    
    print("ğŸ” MONITORING FULL EVALUATION")
    print("=" * 60)
    print(f"ğŸ“ Watching: {results_file}")
    print(f"ğŸ¯ Target: 1172 samples")
    print("=" * 60)
    
    last_count = 0
    start_time = time.time()
    
    while True:
        try:
            if results_file.exists():
                # Read current results
                df = pd.read_csv(results_file)
                current_count = len(df)
                
                if current_count != last_count:
                    # Calculate progress
                    progress = (current_count / 1172) * 100
                    elapsed = time.time() - start_time
                    
                    if current_count > 0:
                        # Estimate remaining time
                        avg_time_per_sample = elapsed / current_count
                        remaining_samples = 1172 - current_count
                        eta_seconds = remaining_samples * avg_time_per_sample
                        eta_minutes = eta_seconds / 60
                        
                        # Calculate current metrics
                        correct_predictions = (df['result'] == 'âœ… CORRECT').sum()
                        current_accuracy = correct_predictions / current_count * 100
                        
                        # Count by type
                        vulnerable_count = (df['ground_truth'] == 'VULNERABLE').sum()
                        safe_count = (df['ground_truth'] == 'SAFE').sum()
                        
                        print(f"\nâ±ï¸  {time.strftime('%H:%M:%S')} - Progress Update:")
                        print(f"ğŸ“Š Samples: {current_count:4d}/1172 ({progress:5.1f}%)")
                        print(f"ğŸ¯ Current Accuracy: {current_accuracy:5.1f}%")
                        print(f"ğŸ”´ Vulnerable: {vulnerable_count:3d}")
                        print(f"ğŸŸ¢ Safe: {safe_count:3d}")
                        print(f"â³ ETA: {eta_minutes:5.1f} minutes")
                        print(f"âš¡ Speed: {current_count/elapsed*60:.1f} samples/min")
                        print("-" * 50)
                    
                    last_count = current_count
                    
                    # Check if complete
                    if current_count >= 1172:
                        print("\nğŸ‰ EVALUATION COMPLETE!")
                        break
            else:
                print(f"ğŸ“ Waiting for results file to be created...")
                
        except Exception as e:
            print(f"âš ï¸  Error reading results: {e}")
        
        time.sleep(10)  # Check every 10 seconds

if __name__ == "__main__":
    monitor_evaluation()
